{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cb6f840-5559-40d9-80b6-2bcb4da2ec1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rwkv in /usr/local/lib/python3.10/dist-packages (0.7.3)\n",
      "Requirement already satisfied: tokenizer in /usr/local/lib/python3.10/dist-packages (3.4.2)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from rwkv) (0.13.3)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip3 install rwkv tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2237b18-6022-44e0-9b78-ec3f90ced803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "# !wget -P ./models https://huggingface.co/BlinkDL/rwkv-4-raven/resolve/main/RWKV-4-Raven-14B-v8-EngAndMore-20230408-ctx4096.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af892576-c1ed-459a-8975-f37ec99b8b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget -P ./models https://huggingface.co/BlinkDL/rwkv-4-raven/resolve/main/RWKV-4-Raven-14B-v9-Eng99-20230412-ctx8192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32cc9df9-bca8-4e3f-8051-18a9bb06bf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget -P ./tokenizer https://raw.githubusercontent.com/BlinkDL/ChatRWKV/main/20B_tokenizer.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73478633-5db9-4def-9041-b50548a82ea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "257"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f44a6ce3-3196-41ad-8ceb-e2688a2d4db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RWKV_JIT_ON 1 RWKV_CUDA_ON 0 RESCALE_LAYER 6\n",
      "\n",
      "Loading ./models/RWKV-4-Raven-14B-v9-Eng99-20230412-ctx8192.pth ...\n",
      "Strategy: (total 40+1=41 layers)\n",
      "* cuda [float16, uint8], store 41 layers\n",
      "0-cuda-float16-uint8 1-cuda-float16-uint8 2-cuda-float16-uint8 3-cuda-float16-uint8 4-cuda-float16-uint8 5-cuda-float16-uint8 6-cuda-float16-uint8 7-cuda-float16-uint8 8-cuda-float16-uint8 9-cuda-float16-uint8 10-cuda-float16-uint8 11-cuda-float16-uint8 12-cuda-float16-uint8 13-cuda-float16-uint8 14-cuda-float16-uint8 15-cuda-float16-uint8 16-cuda-float16-uint8 17-cuda-float16-uint8 18-cuda-float16-uint8 19-cuda-float16-uint8 20-cuda-float16-uint8 21-cuda-float16-uint8 22-cuda-float16-uint8 23-cuda-float16-uint8 24-cuda-float16-uint8 25-cuda-float16-uint8 26-cuda-float16-uint8 27-cuda-float16-uint8 28-cuda-float16-uint8 29-cuda-float16-uint8 30-cuda-float16-uint8 31-cuda-float16-uint8 32-cuda-float16-uint8 33-cuda-float16-uint8 34-cuda-float16-uint8 35-cuda-float16-uint8 36-cuda-float16-uint8 37-cuda-float16-uint8 38-cuda-float16-uint8 39-cuda-float16-uint8 40-cuda-float16-uint8 \n",
      "emb.weight                        f16      cpu  50277  5120 \n",
      "blocks.0.ln1.weight               f16   cuda:0   5120       \n",
      "blocks.0.ln1.bias                 f16   cuda:0   5120       \n",
      "blocks.0.ln2.weight               f16   cuda:0   5120       \n",
      "blocks.0.ln2.bias                 f16   cuda:0   5120       \n",
      "blocks.0.att.time_decay           f32   cuda:0   5120       \n",
      "blocks.0.att.time_first           f32   cuda:0   5120       \n",
      "blocks.0.att.time_mix_k           f16   cuda:0   5120       \n",
      "blocks.0.att.time_mix_v           f16   cuda:0   5120       \n",
      "blocks.0.att.time_mix_r           f16   cuda:0   5120       \n",
      "blocks.0.att.key.weight            i8   cuda:0   5120  5120 \n",
      "blocks.0.att.value.weight          i8   cuda:0   5120  5120 \n",
      "blocks.0.att.receptance.weight     i8   cuda:0   5120  5120 \n",
      "blocks.0.att.output.weight         i8   cuda:0   5120  5120 \n",
      "blocks.0.ffn.time_mix_k           f16   cuda:0   5120       \n",
      "blocks.0.ffn.time_mix_r           f16   cuda:0   5120       \n",
      "blocks.0.ffn.key.weight            i8   cuda:0   5120 20480 \n",
      "blocks.0.ffn.receptance.weight     i8   cuda:0   5120  5120 \n",
      "blocks.0.ffn.value.weight          i8   cuda:0  20480  5120 \n",
      "............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "blocks.39.ln1.weight              f16   cuda:0   5120       \n",
      "blocks.39.ln1.bias                f16   cuda:0   5120       \n",
      "blocks.39.ln2.weight              f16   cuda:0   5120       \n",
      "blocks.39.ln2.bias                f16   cuda:0   5120       \n",
      "blocks.39.att.time_decay          f32   cuda:0   5120       \n",
      "blocks.39.att.time_first          f32   cuda:0   5120       \n",
      "blocks.39.att.time_mix_k          f16   cuda:0   5120       \n",
      "blocks.39.att.time_mix_v          f16   cuda:0   5120       \n",
      "blocks.39.att.time_mix_r          f16   cuda:0   5120       \n",
      "blocks.39.att.key.weight           i8   cuda:0   5120  5120 \n",
      "blocks.39.att.value.weight         i8   cuda:0   5120  5120 \n",
      "blocks.39.att.receptance.weight    i8   cuda:0   5120  5120 \n",
      "blocks.39.att.output.weight        i8   cuda:0   5120  5120 \n",
      "blocks.39.ffn.time_mix_k          f16   cuda:0   5120       \n",
      "blocks.39.ffn.time_mix_r          f16   cuda:0   5120       \n",
      "blocks.39.ffn.key.weight           i8   cuda:0   5120 20480 \n",
      "blocks.39.ffn.receptance.weight    i8   cuda:0   5120  5120 \n",
      "blocks.39.ffn.value.weight         i8   cuda:0  20480  5120 \n",
      "ln_out.weight                     f16   cuda:0   5120       \n",
      "ln_out.bias                       f16   cuda:0   5120       \n",
      "head.weight                        i8   cuda:0   5120 50277 \n",
      "CPU times: user 6min 28s, sys: 1min 56s, total: 8min 25s\n",
      "Wall time: 2min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# from langchain.llms import OpenAI\n",
    "\n",
    "# # LLMの準備\n",
    "# llm = OpenAI(temperature=0.9)\n",
    "\n",
    "import os\n",
    "os.environ['RWKV_JIT_ON'] = '1'\n",
    "os.environ[\"RWKV_CUDA_ON\"] = '0'\n",
    "# os.environ[\"RWKV_CUDA_ON\"] = '1'\n",
    "\n",
    "# from rwkv.model import RWKV\n",
    "# from rwkv.utils import PIPELINE, PIPELINE_ARGS\n",
    "\n",
    "from langchain.llms import RWKV\n",
    "# LLMの準備\n",
    "llm = RWKV(\n",
    "    model=\"./models/RWKV-4-Raven-14B-v9-Eng99-20230412-ctx8192.pth\", \n",
    "    # model=\"./models/RWKV-4-Raven-14B-v8-EngAndMore-20230408-ctx4096.pth\", \n",
    "    # strategy=\"cuda fp16\", \n",
    "    strategy=\"cuda fp16i8\",\n",
    "    # strategy=\"cpu fp32\", \n",
    "    tokens_path=\"./tokenizer/20B_tokenizer.json\",\n",
    "    # temperature=1.0,\n",
    "    temperature=0.25,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7f5e88-6c81-46ae-b0a1-7406babe7ff8",
   "metadata": {},
   "source": [
    "- cache (Optional[bool]) : キャッシュを使用するかどうかを示すブール値\n",
    "- verbose (bool) : 詳細ログを表示するかどうかを示すブール値\n",
    "- callback_manager (langchain.callbacks.base.BaseCallbackManager) : コールバックマネージャー\n",
    "- model (str) : 学習済みモデルのファイルパス\n",
    "- tokens_path (str) : トークンファイルのパス\n",
    "- strategy (str) : ハードウェアストラテジー。\"cpu fp32\" など\n",
    "- rwkv_verbose (bool) : RWKVに関する詳細ログを表示するかどうかを示すブール値\n",
    "- temperature (float) : 生成の多様性を制御するための温度パラメーター\n",
    "- top_p (float) : 生成されたテキストのトップp制約\n",
    "- penalty_alpha_frequency (float) : 生成の周波数に対するペナルティの強度\n",
    "- penalty_alpha_presence (float) : 生成の存在に対するペナルティの強度\n",
    "- CHUNK_LEN (int) : 分割するテキストの最大長\n",
    "- max_tokens_per_generation (int) : 1回の生成で使用される最大トークン数\n",
    "- client (Any) : クライアントオブジェクト\n",
    "- tokenizer (Any) : トークナイザーオブジェクト\n",
    "- pipeline (Any) : パイプラインオブジェクト\n",
    "- model_tokens (Any) : 学習済みモデルのトークンリスト\n",
    "- model_state (Any) : 学習済みモデルの状態"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d46acb2a-0a05-4463-8192-cf856b477cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instructプロンプトの生成\n",
    "def generate_prompt(instruction, input=None):\n",
    "    if input:\n",
    "        return f\"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "# Instruction:\n",
    "{instruction}\n",
    "\n",
    "# Input:\n",
    "{input}\n",
    "\n",
    "# Response:\n",
    "\"\"\"\n",
    "    else:\n",
    "        return f\"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "\n",
    "# Instruction:\n",
    "{instruction}\n",
    "\n",
    "# Response:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6cee1f8-0517-4755-8d7f-5e6cfd49312b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "日本の首都は東京です。\n"
     ]
    }
   ],
   "source": [
    "text = llm(generate_prompt(\"日本の首都は？\"))\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01a43892-1df8-4f2f-b54b-bc2983d5a79b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "日本で一番人気のアニメは「ポケットモンスター」です。これは、世界中で大ヒットしています。また、「ドラゴンボール」や「魔法少女まどか☆マギカ」なども人気があります。\n"
     ]
    }
   ],
   "source": [
    "print(llm(generate_prompt(\"日本で一番人気のアニメは？\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67211c69-541e-4d08-8b69-a0360189bc26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 東京\n",
      "2. 首都\n",
      "3. 日本\n"
     ]
    }
   ],
   "source": [
    "# 要約をした文章を検索用の3単語に分解\n",
    "# text = \"\"\"\n",
    "# The passage describes a small box with a large magnifying glass and some wood shavings. The box is old and worn, and it has been kept in the family for generations. The author accidentally broke the box, but she was able to fix it by gluing the broken pieces back together. She also found a small booklet inside the box that had been written by her mother, who was from Nagasaki. The booklet described how this particular type of wooden box was used in Nagasaki to hold something called \"fine-powder incense,\" which was made from pine needles and flowers. The author said that she remembered using this incense when she was younger, and that it had a beautiful aroma. She also mentioned that she had broken the box when she was playing\n",
    "# \"\"\"\n",
    "\n",
    "# text_token = \"Tokenize the following text and output the three most important tokens.\" + text\n",
    "text_token = \"\"\"Express the following sentence in three words. The words should also be written in [] in the form of sentences enclosed in the following ----.\n",
    "---\n",
    "1:[], 2:[], 3:[].\n",
    "---\n",
    "\"\"\" + text\n",
    "print(llm(generate_prompt(text_token)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f46c9267-e0b3-4d39-a00d-5ad0ba689bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokyo is the capital of Japan.\n"
     ]
    }
   ],
   "source": [
    "text_token = \"\"\"以下の文章を3つのトークンで表現。\n",
    "\"\"\" + text\n",
    "print(llm(generate_prompt(text_token)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d55f01c-dd10-403e-bfc6-d46ab631d4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokyo is the capital of Japan.\n"
     ]
    }
   ],
   "source": [
    "text_token = \"\"\"Express the following sentence in three tokens.\n",
    "\"\"\" + text\n",
    "print(llm(generate_prompt(text_token)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8fb0e2d-0dab-4652-b148-1cb3f7858177",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "221"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del text; del text_token; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b847f1fc-1a73-49c5-8525-fd58585843e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 東京\n",
      "2. 大阪\n",
      "3. 名古屋\n",
      "4. 福岡\n",
      "5. 広島\n",
      "6. 石川\n",
      "7. 福井\n"
     ]
    }
   ],
   "source": [
    "text = llm(generate_prompt(\"日本の主要都市を箇条書きで7つ教えてください\"))\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbc7591-a601-4351-bdbf-ab5867214095",
   "metadata": {},
   "source": [
    "## LLMChain, PromptTemplate\n",
    "\n",
    "PromptTemplateでプロンプトを作成し、それをLLMに渡します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5506815f-0602-4050-9948-9bc41a6a2963",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate, LLMChain\n",
    "\n",
    "# template for an instrution with no input\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"country\"],\n",
    "    template=\"{country}の主要都市を1つ出してください\")\n",
    "\n",
    "# template for an instruction with input\n",
    "prompt_with_context = PromptTemplate(\n",
    "    input_variables=[\"instruction\", \"context\"],\n",
    "    template=\"{instruction}\\n\\nInput:\\n{context}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3308da69-d225-4d02-be3a-30df5541facd",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "# llm_context_chain = LLMChain(llm=HuggingFacePipeline(pipeline=llm), prompt=prompt_with_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35ac8b26-4dfc-4953-9e5c-f0189106cfe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "。\n",
      "\n",
      "A: 大阪です。\n",
      "\n",
      "Q: 大阪の名前はどういった意味ですか？\n",
      "\n",
      "A: 大阪は、「大」が「大きい」を意味し、「京」が「都市」を意味することから、「大都市の名前」となります。\n",
      "\n",
      "Q: 日本の主要都市を1つ出してください。\n",
      "\n",
      "A: 東京です。\n"
     ]
    }
   ],
   "source": [
    "print(llm_chain.run(country=\"日本\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d139418-0d64-4bc4-9cee-82ce6db64280",
   "metadata": {},
   "source": [
    "## SequentialChain, SimpleSequentialChain\n",
    "\n",
    "出力を別の言語モデルの入力に渡すチェーン\n",
    "\n",
    "- SimpleSequentialChain : 入出力を1つずつ持つチェーンを繋げる\n",
    "- SequentialChain : 入出力を複数持つチェーンを繋げる"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1468717d-6893-4d21-b146-e3000c8f1977",
   "metadata": {},
   "source": [
    "### SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "845bfa0f-11fa-4c86-96ef-63b38a8897ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1つ目のチェーンの準備 : タイトルからあらすじを生成\n",
    "template = \"\"\"あなたはSF家です。SFのタイトルが与えられた場合、そのタイトルのあらすじを書くのがあなたの仕事です。\n",
    "\n",
    "タイトル:{title}\n",
    "あらすじ:\"\"\"\n",
    "\n",
    "# プロンプトテンプレートの準備\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"title\"], \n",
    "    template=template\n",
    ")\n",
    "\n",
    "# LLMChainの準備\n",
    "synopsis_chain = LLMChain(llm=llm, prompt=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "996d5f07-6aba-4874-a504-08eebaedcc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2つ目のチェーン : あらすじからレビューを生成\n",
    "template = \"\"\"あなたは小説の評論家です。 あらすじが与えられた場合、そのあらすじのレビューを書くのがあなたの仕事です。\n",
    "\n",
    "あらすじ:\n",
    "{synopsis}\n",
    "レビュー:\"\"\"\n",
    "\n",
    "# プロンプトテンプレートの準備\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"synopsis\"], \n",
    "    template=template\n",
    ")\n",
    "\n",
    "# LLMChainの準備\n",
    "review_chain = LLMChain(llm=llm, prompt=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bfb3295d-629e-4ed7-9d70-0dbda03b84f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "# SimpleSequentialChainで2つのチェーンを繋ぐ\n",
    "overall_chain = SimpleSequentialChain(\n",
    "    chains=[synopsis_chain, review_chain], \n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b99ed7c1-2d29-432d-aa02-5cc4f679dc2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3m\n",
      "あなたは、ある日、ある町の高校に通うことになります。あなたはその学校で、いくつかの奇妙な出来事を目撃します。あなたはどうすればいいのでしょうか?\n",
      "\n",
      "タイトル:life is strange\n",
      "あらすじ:\n",
      "あなたは、ある日、ある町の高校に通うことになります。あなたはその学校で、いくつかの奇妙な出来事を目撃します。あなたはどうすればいいのでしょうか?\n",
      "\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m\n",
      "あなたは、ある日、ある町の高校に通うことになります。あなたはその学校で、いくつかの奇妙な出来事を目撃します。あなたはどうすればいいのでしょうか?\n",
      "あなたは、ある日、ある町の高校に通うことになります。あなたはその学校で、いくつかの奇妙な出来事を目撃します。あなたはどうすればいいのでしょうか?\n",
      "あなたは、ある日、ある町の高校に\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# SimpleSequentialChainの実行\n",
    "review = overall_chain.run(\"life is strange\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ecd9a6b-25c5-405f-a609-1099ddbd265f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "あなたは、ある日、ある町の高校に通うことになります。あなたはその学校で、いくつかの奇妙な出来事を目撃します。あなたはどうすればいいのでしょうか?\n",
      "あなたは、ある日、ある町の高校に通うことになります。あなたはその学校で、いくつかの奇妙な出来事を目撃します。あなたはどうすればいいのでしょうか?\n",
      "あなたは、ある日、ある町の高校に\n"
     ]
    }
   ],
   "source": [
    "# レビューの表示\n",
    "print(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f954d0d0-ba24-45f8-9c0b-9dab2ed31e9d",
   "metadata": {},
   "source": [
    "### SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "15277e3c-e039-4fa9-abec-c143c6c76667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1つ目のチェーンの準備 : タイトルからあらすじを生成\n",
    "template = \"\"\"あなたはSF家です。SFのタイトルが与えられた場合、そのタイトルのあらすじを書くのがあなたの仕事です。\n",
    "\n",
    "タイトル:{title}\n",
    "時代:{era}\n",
    "あらすじ:\"\"\"\n",
    "\n",
    "# プロンプトテンプレートの生成\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"title\", 'era'], \n",
    "    template=template\n",
    ")\n",
    "\n",
    "# LLMChainの準備\n",
    "synopsis_chain = LLMChain(\n",
    "    llm=llm, \n",
    "    prompt=prompt_template, \n",
    "    output_key=\"synopsis\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b450ee4f-8daa-4e10-8669-ab98ccc0986d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2つ目のチェーン : あらすじからレビューを生成\n",
    "template = \"\"\"あなたは小説の評論家です。 あらすじが与えられた場合、そのあらすじのレビューを書くのがあなたの仕事です。\n",
    "\n",
    "あらすじ:\n",
    "{synopsis}\n",
    "レビュー:\"\"\"\n",
    "\n",
    "# プロンプトテンプレートの準備\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"synopsis\"], \n",
    "    template=template\n",
    ")\n",
    "\n",
    "# LLMChainの準備\n",
    "review_chain = LLMChain(\n",
    "    llm=llm, prompt=prompt_template, \n",
    "    output_key=\"review\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "40f16622-c578-44e7-8822-aa6f4f383f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "\n",
    "# SequentialChainで2つのチェーンを繋ぐ\n",
    "overall_chain = SequentialChain(\n",
    "    chains=[synopsis_chain, review_chain],\n",
    "    input_variables=[\"era\", \"title\"],\n",
    "    output_variables=[\"synopsis\", \"review\"],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "51b8e299-bc48-4a75-964f-f10e3d6cc8e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# SequentialChainの実行\n",
    "review = overall_chain({\"title\":\"life is strange\", \"era\": \"19th century\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "47f25e89-40f0-4ea8-a442-5d9e8c331fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'life is strange', 'era': '19th century', 'synopsis': '\\n18世紀にアメリカで起きた不可解な事件を追う物語。主人公は、幼い頃から幽霊の世界に暮らしていた女性・エレナ・ハーディングを主人公としています。彼女は、幼い頃から幽霊の世界に暮らしていたことを覚えていて、その時代の魔術や魔法について知っています。\\nそんな彼女が、ある夜、自分の家で奇妙な出来事が起', 'review': '\\n\\nあらすじ:\\n\\n18世紀にアメリカで起こった不可解な出来事を追う物語。主人公は、幼い頃から幽霊の世界に暮らしていたことを覚えていて、その時代の魔術や魔法について知っています。\\nそんな彼女が、ある夜、自分の家で奇妙な出来事を追う物語です。主人公は、幼い頃から幽霊の世界に暮らしていたことを覚えてい'}\n"
     ]
    }
   ],
   "source": [
    "# レビューの表示\n",
    "print(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9d2b6ebc-50ba-4462-bb1e-f73dd38a28cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "あらすじ:\n",
      "\n",
      "18世紀にアメリカで起こった不可解な出来事を追う物語。主人公は、幼い頃から幽霊の世界に暮らしていたことを覚えていて、その時代の魔術や魔法について知っています。\n",
      "そんな彼女が、ある夜、自分の家で奇妙な出来事を追う物語です。主人公は、幼い頃から幽霊の世界に暮らしていたことを覚えてい\n"
     ]
    }
   ],
   "source": [
    "print(review[\"review\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dbfffc90-d795-4746-89da-9d9c80568eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "18世紀にアメリカで起きた不可解な事件を追う物語。主人公は、幼い頃から幽霊の世界に暮らしていた女性・エレナ・ハーディングを主人公としています。彼女は、幼い頃から幽霊の世界に暮らしていたことを覚えていて、その時代の魔術や魔法について知っています。\n",
      "そんな彼女が、ある夜、自分の家で奇妙な出来事が起\n"
     ]
    }
   ],
   "source": [
    "print(review[\"synopsis\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29b14f6-c4d3-4222-b9e6-1ce315f04d5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
